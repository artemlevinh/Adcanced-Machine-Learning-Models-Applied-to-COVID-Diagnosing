{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhqZH5t9FBI3"
   },
   "source": [
    "<p align=\"center\"><h1 align=\"center\">Adcanced Machine Learning Models Applied to COVID Diagnosing <br> CNN Model 3 with Fine Tuning<br>Spring 2024 <br> Nicholas Choong, Qiankun Li</h1>\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we train a CNN model and the project leverages the flexibility and efficiency of the CNN by fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gd7JyCeQFBI9"
   },
   "source": [
    "# **STEP 1: Import packages and extract the dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uhYYvsyNXC6",
    "outputId": "7b007f90-e837-4ddc-d41d-59880453a0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in c:\\users\\l\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\l\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Mu2zq86HwZFU"
   },
   "outputs": [],
   "source": [
    "# Load libraries and then download data\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerastuner import RandomSearch\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "XO0w1yjsNXC6",
    "outputId": "d401ed8f-fe11-4d7b-9f51-0340420ff26e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your dataset zip file\n",
    "zip_file_path = r'C:\\Users\\l\\Downloads\\COVID-19_Radiography_Dataset.zip'\n",
    "\n",
    "# Specify the extraction path, the empty file location you want to put your files in \n",
    "extraction_path = r'C:\\Users\\l\\Downloads\\Extracted Dataset'\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "print(\"Dataset extracted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7veU5LiFBI-"
   },
   "source": [
    "# **STEP 2: Prepare the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dWzvKPdewbLz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images for each category: [3616, 10192, 1345]\n"
     ]
    }
   ],
   "source": [
    "# Extracting all filenames iteratively\n",
    "base_path = r'C:\\Users\\l\\Downloads\\Extracted Dataset\\COVID-19_Radiography_Dataset'\n",
    "categories = ['COVID/images', 'Normal/images', 'Viral Pneumonia/images']\n",
    "\n",
    "# load file names to fnames list object\n",
    "fnames = []\n",
    "for category in categories:\n",
    "    image_folder = os.path.join(base_path, category)\n",
    "    file_names = os.listdir(image_folder)\n",
    "    full_path = [os.path.join(image_folder, file_name) for file_name in file_names]\n",
    "    fnames.append(full_path)\n",
    "\n",
    "\n",
    "print('number of images for each category:', [len(f) for f in fnames])\n",
    "#print(fnames[0:2]) #examples of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4u-QBVz8fGYR"
   },
   "outputs": [],
   "source": [
    "#Reduce number of images to first 1345 for each category\n",
    "fnames[0] = fnames[0][0:1344]\n",
    "fnames[1] = fnames[1][0:1344]\n",
    "fnames[2] = fnames[2][0:1344]\n",
    "\n",
    "# Reduce number of images to first 1345 for each category to balance the dataset\n",
    "fnames = [f[:1344] for f in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR9fq2m_wx3V",
    "outputId": "6a8e92ba-3071-4b73-86d9-38e4bfb3c515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image shape: (192, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import image, load to array of shape height, width, channels, then min/max transform.\n",
    "# Write preprocessor that will match up with model's expected input shape.\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define the image preprocessor\n",
    "def preprocessor(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((192, 192))  # Import image, ensure it's in RGB and resize.\n",
    "    img = (np.float32(img) - 1.) / (255 - 1.)  # Min-max transform.\n",
    "    img = img.reshape((192, 192, 3))  # Create final shape as array with correct dimensions for Keras.\n",
    "    return img\n",
    "\n",
    "# Try on a single image file (imports file and preprocesses it to data with the expected shape)\n",
    "image_path = os.path.join(base_path, 'COVID/images/COVID-2273.png')\n",
    "img_shape = preprocessor(image_path).shape\n",
    "print('Processed image shape:', img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "svHoZ-SXw9qX"
   },
   "outputs": [],
   "source": [
    "#Import image files iteratively and preprocess them into array of correctly structured data\n",
    "# Create list of file paths\n",
    "image_filepaths=fnames[0]+fnames[1]+fnames[2]\n",
    "\n",
    "# Iteratively import and preprocess data using map function\n",
    "# map functions apply your preprocessor function one step at a time to each filepath\n",
    "preprocessed_image_data=list(map(preprocessor, image_filepaths))\n",
    "\n",
    "# Object needs to be an array rather than a list for Keras (map returns to list object)\n",
    "X = np.array(preprocessed_image_data) # Assigning to X to highlight that this represents feature input data for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "pU0Da0m8x9_n",
    "outputId": "e9fa6739-cf7a-4b65-a9e6-3b54faafaa97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images for each category: [1344, 1344, 1344]\n",
      "4032\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COVID</th>\n",
       "      <th>NORMAL</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COVID  NORMAL  PNEUMONIA\n",
       "0      True   False      False\n",
       "1      True   False      False\n",
       "2      True   False      False\n",
       "3      True   False      False\n",
       "4      True   False      False\n",
       "...     ...     ...        ...\n",
       "4027  False   False       True\n",
       "4028  False   False       True\n",
       "4029  False   False       True\n",
       "4030  False   False       True\n",
       "4031  False   False       True\n",
       "\n",
       "[4032 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create y data made up of correctly ordered labels from file folders\n",
    "from itertools import repeat\n",
    "\n",
    "# Recall that we have five folders with the following number of images in each folder\n",
    "#...corresponding to each flower type\n",
    "print('number of images for each category:', [len(f) for f in fnames])\n",
    "covid=list(repeat(\"COVID\", 1344))\n",
    "normal=list(repeat(\"NORMAL\", 1344))\n",
    "pneumonia=list(repeat(\"PNEUMONIA\", 1344))\n",
    "\n",
    "#combine into single list of y labels\n",
    "y_labels = covid + normal + pneumonia\n",
    "\n",
    "#check length, same as X above\n",
    "print(len(y_labels))\n",
    "\n",
    "# Need to one hot encode for Keras.  Let's use Pandas\n",
    "y = pd.get_dummies(y_labels)\n",
    "\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base_path is the path your data is extracted to\n",
    "base_path = r'C:\\Users\\l\\Downloads\\Extracted Dataset\\COVID-19_Radiography_Dataset'\n",
    "categories = ['COVID/images', 'Normal/images', 'Viral Pneumonia/images']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JuzjSomQNXC8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting up the data augmentation configuration\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 3: Splitting Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TImfyLlxy1Vx",
    "outputId": "ac0d912c-f1c3-4284-f36b-48a31e83dc7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1291, 192, 192, 3), (1291, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======Train test split resized images (Hackathon Note!! Use same train test split to be able to submit predictions to leaderboard!)=======================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.32, random_state = 1987)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_NdLXfABhpTC"
   },
   "outputs": [],
   "source": [
    "#Clear objects from memory\n",
    "del(X)\n",
    "del(y)\n",
    "del(preprocessed_image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "79LOCIg-hOVg"
   },
   "outputs": [],
   "source": [
    "#Save data to be able to reload quickly if memory crashes or if you run Runtime>Restart Runtime\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(X_train, file)\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('X_test.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(X_test, file)\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('y_train.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(y_train, file)\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('y_test.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(y_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dEMdwHosjmgt"
   },
   "outputs": [],
   "source": [
    "#If you run out of Colab memory restart runtime, reload data and try again\n",
    "import pickle\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open('X_train.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    X_train = pickle.load(file)\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open('y_train.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    y_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxw-xZxIFBJA"
   },
   "source": [
    "# **STEP 4: Setting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJUIZsqMJ7KS",
    "outputId": "b8f07c87-1db4-4dd9-bdd2-13204b6d9075"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(192, 192, 3)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Tuning the dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(192, 192, 3)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Tuning the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 5: Fine-tuning by Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000026C0E0874A0> (of type <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkerastuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomSearch\n\u001b[1;32m----> 3\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of trials to run\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of models that should be built and fit for each trial\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Directory to save logs and models\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcnn_hyperparam_tuning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Display search space summary\u001b[39;00m\n\u001b[0;32m     13\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch_space_summary()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\tuners\\randomsearch.py:174\u001b[0m, in \u001b[0;36mRandomSearch.__init__\u001b[1;34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m seed\n\u001b[0;32m    164\u001b[0m oracle \u001b[38;5;241m=\u001b[39m RandomSearchOracle(\n\u001b[0;32m    165\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[0;32m    166\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m     max_consecutive_failed_trials\u001b[38;5;241m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[0;32m    173\u001b[0m )\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:122\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     )\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_size \u001b[38;5;241m=\u001b[39m max_model_size\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:132\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Run in distributed mode.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mhas_chief_oracle() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mis_chief_oracle():\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Proxies requests to the chief oracle.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:192\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_activate_all_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:149\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_space()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# Update the recorded scopes.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(hp):\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(Conv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py:91\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     89\u001b[0m         layer \u001b[38;5;241m=\u001b[39m origin_layer\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Layer):\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly instances of `keras.Layer` can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded to a Sequential model. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll layers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have unique names. Name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe name of a layer in this model. Update the `name` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pass a unique name.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000026C0E0874A0> (of type <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of trials to run\n",
    "    executions_per_trial=1,  # Number of models that should be built and fit for each trial\n",
    "    directory='my_dir',  # Directory to save logs and models\n",
    "    project_name='cnn_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Display search space summary\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Start the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "# Get the best model\n",
    "cnn_model3 = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Summary of the best model\n",
    "cnn_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
