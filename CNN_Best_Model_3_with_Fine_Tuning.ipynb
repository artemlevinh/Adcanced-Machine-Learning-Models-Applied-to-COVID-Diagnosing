{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhqZH5t9FBI3"
   },
   "source": [
    "<p align=\"center\"><h1 align=\"center\">Adcanced Machine Learning Models Applied to COVID Diagnosing <br> CNN Model 3 with Fine Tuning<br>Spring 2024 <br> Nicholas Choong, Qiankun Li</h1>\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we train a CNN model and the project leverages the flexibility and efficiency of the CNN by fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gd7JyCeQFBI9"
   },
   "source": [
    "# **STEP 1: Import packages and extract the dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Mu2zq86HwZFU"
   },
   "outputs": [],
   "source": [
    "# Load libraries and then download data\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerastuner import RandomSearch\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "XO0w1yjsNXC6",
    "outputId": "d401ed8f-fe11-4d7b-9f51-0340420ff26e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your dataset zip file\n",
    "zip_file_path = r'/Users/nicholaschoong/Documents/Columbia/qmss/Sem 2/ML/Data/Assignment 2 Data/COVID-19_Radiography_Dataset.zip'\n",
    "\n",
    "# Specify the extraction path, the empty file location you want to put your files in \n",
    "extraction_path = r'/Users/nicholaschoong/Documents/Columbia/qmss/Sem 2/ML/Data/Assignment 2 Data/Extracted Dataset'\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "print(\"Dataset extracted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7veU5LiFBI-"
   },
   "source": [
    "# **STEP 2: Prepare the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dWzvKPdewbLz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images for each category: [3616, 10192, 1345]\n"
     ]
    }
   ],
   "source": [
    "# Extracting all filenames iteratively\n",
    "base_path = r'/Users/nicholaschoong/Documents/Columbia/qmss/Sem 2/ML/Data/Assignment 2 Data/Extracted Dataset/COVID-19_Radiography_Dataset'\n",
    "categories = ['COVID/images', 'Normal/images', 'Viral Pneumonia/images']\n",
    "\n",
    "# load file names to fnames list object\n",
    "fnames = []\n",
    "for category in categories:\n",
    "    image_folder = os.path.join(base_path, category)\n",
    "    file_names = os.listdir(image_folder)\n",
    "    full_path = [os.path.join(image_folder, file_name) for file_name in file_names]\n",
    "    fnames.append(full_path)\n",
    "\n",
    "\n",
    "print('number of images for each category:', [len(f) for f in fnames])\n",
    "#print(fnames[0:2]) #examples of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4u-QBVz8fGYR"
   },
   "outputs": [],
   "source": [
    "#Reduce number of images to first 1345 for each category\n",
    "fnames[0] = fnames[0][0:1344]\n",
    "fnames[1] = fnames[1][0:1344]\n",
    "fnames[2] = fnames[2][0:1344]\n",
    "\n",
    "# Reduce number of images to first 1345 for each category to balance the dataset\n",
    "fnames = [f[:1344] for f in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR9fq2m_wx3V",
    "outputId": "6a8e92ba-3071-4b73-86d9-38e4bfb3c515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image shape: (192, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import image, load to array of shape height, width, channels, then min/max transform.\n",
    "# Write preprocessor that will match up with model's expected input shape.\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define the image preprocessor\n",
    "def preprocessor(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((192, 192))  # Import image, ensure it's in RGB and resize.\n",
    "    img = (np.float32(img) - 1.) / (255 - 1.)  # Min-max transform.\n",
    "    img = img.reshape((192, 192, 3))  # Create final shape as array with correct dimensions for Keras.\n",
    "    return img\n",
    "\n",
    "# Try on a single image file (imports file and preprocesses it to data with the expected shape)\n",
    "image_path = os.path.join(base_path, 'COVID/images/COVID-2273.png')\n",
    "img_shape = preprocessor(image_path).shape\n",
    "print('Processed image shape:', img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "svHoZ-SXw9qX"
   },
   "outputs": [],
   "source": [
    "#Import image files iteratively and preprocess them into array of correctly structured data\n",
    "# Create list of file paths\n",
    "image_filepaths=fnames[0]+fnames[1]+fnames[2]\n",
    "\n",
    "# Iteratively import and preprocess data using map function\n",
    "# map functions apply your preprocessor function one step at a time to each filepath\n",
    "preprocessed_image_data=list(map(preprocessor, image_filepaths))\n",
    "\n",
    "# Object needs to be an array rather than a list for Keras (map returns to list object)\n",
    "X = np.array(preprocessed_image_data) # Assigning to X to highlight that this represents feature input data for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "pU0Da0m8x9_n",
    "outputId": "e9fa6739-cf7a-4b65-a9e6-3b54faafaa97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images for each category: [1344, 1344, 1344]\n",
      "4032\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COVID</th>\n",
       "      <th>NORMAL</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COVID  NORMAL  PNEUMONIA\n",
       "0      True   False      False\n",
       "1      True   False      False\n",
       "2      True   False      False\n",
       "3      True   False      False\n",
       "4      True   False      False\n",
       "...     ...     ...        ...\n",
       "4027  False   False       True\n",
       "4028  False   False       True\n",
       "4029  False   False       True\n",
       "4030  False   False       True\n",
       "4031  False   False       True\n",
       "\n",
       "[4032 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create y data made up of correctly ordered labels from file folders\n",
    "from itertools import repeat\n",
    "\n",
    "# Recall that we have five folders with the following number of images in each folder\n",
    "#...corresponding to each flower type\n",
    "print('number of images for each category:', [len(f) for f in fnames])\n",
    "covid=list(repeat(\"COVID\", 1344))\n",
    "normal=list(repeat(\"NORMAL\", 1344))\n",
    "pneumonia=list(repeat(\"PNEUMONIA\", 1344))\n",
    "\n",
    "#combine into single list of y labels\n",
    "y_labels = covid + normal + pneumonia\n",
    "\n",
    "#check length, same as X above\n",
    "print(len(y_labels))\n",
    "\n",
    "# Need to one hot encode for Keras.  Let's use Pandas\n",
    "y = pd.get_dummies(y_labels)\n",
    "\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base_path is the path your data is extracted to\n",
    "base_path = r'C:\\Users\\l\\Downloads\\Extracted Dataset\\COVID-19_Radiography_Dataset'\n",
    "categories = ['COVID/images', 'Normal/images', 'Viral Pneumonia/images']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JuzjSomQNXC8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting up the data augmentation configuration\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 3: Splitting Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TImfyLlxy1Vx",
    "outputId": "ac0d912c-f1c3-4284-f36b-48a31e83dc7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1291, 192, 192, 3), (1291, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======Train test split resized images (Hackathon Note!! Use same train test split to be able to submit predictions to leaderboard!)=======================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.32, random_state = 1987)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_NdLXfABhpTC"
   },
   "outputs": [],
   "source": [
    "#Clear objects from memory\n",
    "del(X)\n",
    "del(y)\n",
    "del(preprocessed_image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "79LOCIg-hOVg"
   },
   "outputs": [],
   "source": [
    "#Save data to be able to reload quickly if memory crashes or if you run Runtime>Restart Runtime\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(X_train, file)\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('X_test.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(X_test, file)\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('y_train.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(y_train, file)\n",
    "\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('y_test.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(y_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dEMdwHosjmgt"
   },
   "outputs": [],
   "source": [
    "#If you run out of Colab memory restart runtime, reload data and try again\n",
    "import pickle\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open('X_train.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    X_train = pickle.load(file)\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open('y_train.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    y_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxw-xZxIFBJA"
   },
   "source": [
    "# **STEP 4: Setting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJUIZsqMJ7KS",
    "outputId": "b8f07c87-1db4-4dd9-bdd2-13204b6d9075"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(192, 192, 3)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Tuning the dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(192, 192, 3)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Tuning the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 5: Fine-tuning by Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 18s]\n",
      "val_accuracy: 0.8287795782089233\n",
      "\n",
      "Best val_accuracy So Far: 0.8834244012832642\n",
      "Total elapsed time: 00h 14m 05s\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 192, 192, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 192, 192, 32)      1056      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 96, 96, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 96, 96, 32)        1056      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 48, 48, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 48, 48, 64)        4160      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 24, 24, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 128)       16512     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 12, 12, 512)       262656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10417507 (39.74 MB)\n",
      "Trainable params: 10417507 (39.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of trials to run\n",
    "    executions_per_trial=1,  # Number of models that should be built and fit for each trial\n",
    "    directory='my_dir',  # Directory to save logs and models\n",
    "    project_name='cnn_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Display search space summary\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Start the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "# Get the best model\n",
    "cnn_model3 = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Summary of the best model\n",
    "cnn_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 39ms/step - loss: 0.2941 - accuracy: 0.8947\n",
      "Test Loss: 0.29411178827285767, Test Accuracy: 0.8946552872657776\n"
     ]
    }
   ],
   "source": [
    "# After finding the best model, evaluate it on your test set:\n",
    "test_loss, test_accuracy = cnn_model3.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
